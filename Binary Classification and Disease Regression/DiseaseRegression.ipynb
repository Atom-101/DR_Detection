{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import re\n",
    "# import math\n",
    "# import collections\n",
    "\n",
    "# from collections import Counter\n",
    "# import json\n",
    "\n",
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.basic_train import *\n",
    "from fastai.vision.learner import *\n",
    "\n",
    "import cv2\n",
    "\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(res=224,bs=16):\n",
    "    np.random.seed(420)\n",
    "    df = pd.read_csv('../Data/CombinedDiseased.csv')\n",
    "    \n",
    "    tfms = [[rotate(degrees=(-5,5),p=0.5),\n",
    "         flip_lr(p=0.5),\n",
    "         contrast(scale=(0.7,1),p=0.5)],[]]\n",
    "    tfms[0].extend(rand_resize_crop(res,max_scale=2))\n",
    "    \n",
    "    data = (ImageList.from_df(df,'')\n",
    "        .split_by_rand_pct(0.1) \n",
    "        .label_from_df(cols='diagnosis',label_cls=FloatList) \n",
    "        .transform(tfms,size=res,resize_method=ResizeMethod.SQUISH,padding_mode='zeros') \n",
    "        .databunch(bs=bs,num_workers=os.cpu_count())).normalize(imagenet_stats)  \n",
    "    return data\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the entire model (stem, all blocks, and head)\n",
    "GlobalParams = collections.namedtuple('GlobalParams', [\n",
    "    'batch_norm_momentum', 'batch_norm_epsilon', 'dropout_rate',\n",
    "    'num_classes', 'width_coefficient', 'depth_coefficient',\n",
    "    'depth_divisor', 'min_depth', 'drop_connect_rate', 'image_size'])\n",
    "\n",
    "\n",
    "# Parameters for an individual model block\n",
    "BlockArgs = collections.namedtuple('BlockArgs', [\n",
    "    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n",
    "    'expand_ratio', 'id_skip', 'stride', 'se_ratio'])\n",
    "\n",
    "\n",
    "# Change namedtuple defaults\n",
    "GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)\n",
    "BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n",
    "\n",
    "\n",
    "def relu_fn(x):\n",
    "    \"\"\" Swish activation function \"\"\"\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def round_filters(filters, global_params):\n",
    "    \"\"\" Calculate and round number of filters based on depth multiplier. \"\"\"\n",
    "    multiplier = global_params.width_coefficient\n",
    "    if not multiplier:\n",
    "        return filters\n",
    "    divisor = global_params.depth_divisor\n",
    "    min_depth = global_params.min_depth\n",
    "    filters *= multiplier\n",
    "    min_depth = min_depth or divisor\n",
    "    new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)\n",
    "    if new_filters < 0.9 * filters:  # prevent rounding by more than 10%\n",
    "        new_filters += divisor\n",
    "    return int(new_filters)\n",
    "\n",
    "\n",
    "def round_repeats(repeats, global_params):\n",
    "    \"\"\" Round number of filters based on depth multiplier. \"\"\"\n",
    "    multiplier = global_params.depth_coefficient\n",
    "    if not multiplier:\n",
    "        return repeats\n",
    "    return int(math.ceil(multiplier * repeats))\n",
    "\n",
    "\n",
    "def drop_connect(inputs, p, training):\n",
    "    \"\"\" Drop connect. \"\"\"\n",
    "    if not training: return inputs\n",
    "    batch_size = inputs.shape[0]\n",
    "    keep_prob = 1 - p\n",
    "    random_tensor = keep_prob\n",
    "    random_tensor += torch.rand([batch_size, 1, 1, 1], dtype=inputs.dtype, device=inputs.device)\n",
    "    binary_tensor = torch.floor(random_tensor)\n",
    "    output = inputs / keep_prob * binary_tensor\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_same_padding_conv2d(image_size=None):\n",
    "    \"\"\" Chooses static padding if you have specified an image size, and dynamic padding otherwise.\n",
    "        Static padding is necessary for ONNX exporting of models. \"\"\"\n",
    "    if image_size is None:\n",
    "        return Conv2dDynamicSamePadding\n",
    "    else:\n",
    "        return partial(Conv2dStaticSamePadding, image_size=image_size)\n",
    "\n",
    "class Conv2dDynamicSamePadding(nn.Conv2d):\n",
    "    \"\"\" 2D Convolutions like TensorFlow, for a dynamic image size \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n",
    "        self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]]*2\n",
    "\n",
    "    def forward(self, x):\n",
    "        ih, iw = x.size()[-2:]\n",
    "        kh, kw = self.weight.size()[-2:]\n",
    "        sh, sw = self.stride\n",
    "        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n",
    "        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
    "        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(x, [pad_w//2, pad_w - pad_w//2, pad_h//2, pad_h - pad_h//2])\n",
    "        return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "\n",
    "class Conv2dStaticSamePadding(nn.Conv2d):\n",
    "    \"\"\" 2D Convolutions like TensorFlow, for a fixed image size\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, image_size=None, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, **kwargs)\n",
    "        self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]] * 2\n",
    "\n",
    "        # Calculate padding based on image size and save it\n",
    "        assert image_size is not None\n",
    "        ih, iw = image_size if type(image_size) == list else [image_size, image_size]\n",
    "        kh, kw = self.weight.size()[-2:]\n",
    "        sh, sw = self.stride\n",
    "        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n",
    "        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
    "        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            self.static_padding = nn.ZeroPad2d((pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2))\n",
    "        else:\n",
    "            self.static_padding = Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.static_padding(x)\n",
    "        x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input\n",
    "\n",
    "\n",
    "########################################################################\n",
    "############## HELPERS FUNCTIONS FOR LOADING MODEL PARAMS ##############\n",
    "########################################################################\n",
    "\n",
    "\n",
    "def efficientnet_params(model_name):\n",
    "    \"\"\" Map EfficientNet model name to parameter coefficients. \"\"\"\n",
    "    params_dict = {\n",
    "        # Coefficients:   width,depth,res,dropout\n",
    "        'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n",
    "        'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n",
    "        'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n",
    "        'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n",
    "        'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n",
    "        'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n",
    "        'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n",
    "        'efficientnet-b7': (2.0, 3.1, 600, 0.5),\n",
    "    }\n",
    "    return params_dict[model_name]\n",
    "\n",
    "\n",
    "class BlockDecoder(object):\n",
    "    \"\"\" Block Decoder for readability, straight from the official TensorFlow repository \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _decode_block_string(block_string):\n",
    "        \"\"\" Gets a block through a string notation of arguments. \"\"\"\n",
    "        assert isinstance(block_string, str)\n",
    "\n",
    "        ops = block_string.split('_')\n",
    "        options = {}\n",
    "        for op in ops:\n",
    "            splits = re.split(r'(\\d.*)', op)\n",
    "            if len(splits) >= 2:\n",
    "                key, value = splits[:2]\n",
    "                options[key] = value\n",
    "\n",
    "        # Check stride\n",
    "        assert (('s' in options and len(options['s']) == 1) or\n",
    "                (len(options['s']) == 2 and options['s'][0] == options['s'][1]))\n",
    "\n",
    "        return BlockArgs(\n",
    "            kernel_size=int(options['k']),\n",
    "            num_repeat=int(options['r']),\n",
    "            input_filters=int(options['i']),\n",
    "            output_filters=int(options['o']),\n",
    "            expand_ratio=int(options['e']),\n",
    "            id_skip=('noskip' not in block_string),\n",
    "            se_ratio=float(options['se']) if 'se' in options else None,\n",
    "            stride=[int(options['s'][0])])\n",
    "\n",
    "    @staticmethod\n",
    "    def _encode_block_string(block):\n",
    "        \"\"\"Encodes a block to a string.\"\"\"\n",
    "        args = [\n",
    "            'r%d' % block.num_repeat,\n",
    "            'k%d' % block.kernel_size,\n",
    "            's%d%d' % (block.strides[0], block.strides[1]),\n",
    "            'e%s' % block.expand_ratio,\n",
    "            'i%d' % block.input_filters,\n",
    "            'o%d' % block.output_filters\n",
    "        ]\n",
    "        if 0 < block.se_ratio <= 1:\n",
    "            args.append('se%s' % block.se_ratio)\n",
    "        if block.id_skip is False:\n",
    "            args.append('noskip')\n",
    "        return '_'.join(args)\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(string_list):\n",
    "        \"\"\"\n",
    "        Decodes a list of string notations to specify blocks inside the network.\n",
    "\n",
    "        :param string_list: a list of strings, each string is a notation of block\n",
    "        :return: a list of BlockArgs namedtuples of block args\n",
    "        \"\"\"\n",
    "        assert isinstance(string_list, list)\n",
    "        blocks_args = []\n",
    "        for block_string in string_list:\n",
    "            blocks_args.append(BlockDecoder._decode_block_string(block_string))\n",
    "        return blocks_args\n",
    "\n",
    "    @staticmethod\n",
    "    def encode(blocks_args):\n",
    "        \"\"\"\n",
    "        Encodes a list of BlockArgs to a list of strings.\n",
    "\n",
    "        :param blocks_args: a list of BlockArgs namedtuples of block args\n",
    "        :return: a list of strings, each string is a notation of block\n",
    "        \"\"\"\n",
    "        block_strings = []\n",
    "        for block in blocks_args:\n",
    "            block_strings.append(BlockDecoder._encode_block_string(block))\n",
    "        return block_strings\n",
    "\n",
    "\n",
    "def efficientnet(width_coefficient=None, depth_coefficient=None, dropout_rate=0.2,\n",
    "                 drop_connect_rate=0.2, image_size=None, num_classes=1000):\n",
    "    \"\"\" Creates a efficientnet model. \"\"\"\n",
    "\n",
    "    blocks_args = [\n",
    "        'r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25',\n",
    "        'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25',\n",
    "        'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25',\n",
    "        'r1_k3_s11_e6_i192_o320_se0.25',\n",
    "    ]\n",
    "    blocks_args = BlockDecoder.decode(blocks_args)\n",
    "\n",
    "    global_params = GlobalParams(\n",
    "        batch_norm_momentum=0.99,\n",
    "        batch_norm_epsilon=1e-3,\n",
    "        dropout_rate=dropout_rate,\n",
    "        drop_connect_rate=drop_connect_rate,\n",
    "        # data_format='channels_last',  # removed, this is always true in PyTorch\n",
    "        num_classes=num_classes,\n",
    "        width_coefficient=width_coefficient,\n",
    "        depth_coefficient=depth_coefficient,\n",
    "        depth_divisor=8,\n",
    "        min_depth=None,\n",
    "        image_size=image_size,\n",
    "    )\n",
    "\n",
    "    return blocks_args, global_params\n",
    "\n",
    "\n",
    "def get_model_params(model_name, override_params):\n",
    "    \"\"\" Get the block args and global params for a given model \"\"\"\n",
    "    if model_name.startswith('efficientnet'):\n",
    "        w, d, s, p = efficientnet_params(model_name)\n",
    "        # note: all models have drop connect rate = 0.2\n",
    "        blocks_args, global_params = efficientnet(\n",
    "            width_coefficient=w, depth_coefficient=d, dropout_rate=p, image_size=s)\n",
    "    else:\n",
    "        raise NotImplementedError('model name is not pre-defined: %s' % model_name)\n",
    "    if override_params:\n",
    "        # ValueError will be raised here if override_params has fields not included in global_params.\n",
    "        global_params = global_params._replace(**override_params)\n",
    "    return blocks_args, global_params\n",
    "\n",
    "\n",
    "url_map = {\n",
    "    'efficientnet-b0': 'http://storage.googleapis.com/public-models/efficientnet-b0-08094119.pth',\n",
    "    'efficientnet-b1': 'http://storage.googleapis.com/public-models/efficientnet-b1-dbc7070a.pth',\n",
    "    'efficientnet-b2': 'http://storage.googleapis.com/public-models/efficientnet-b2-27687264.pth',\n",
    "    'efficientnet-b3': 'http://storage.googleapis.com/public-models/efficientnet-b3-c8376fa2.pth',\n",
    "    'efficientnet-b4': 'http://storage.googleapis.com/public-models/efficientnet-b4-e116e8b3.pth',\n",
    "    'efficientnet-b5': 'http://storage.googleapis.com/public-models/efficientnet-b5-586e6cc6.pth',\n",
    "}\n",
    "\n",
    "def load_pretrained_weights(model, model_name, load_fc=True):\n",
    "    \"\"\" Loads pretrained weights, and downloads if loading for the first time. \"\"\"\n",
    "    state_dict = model_zoo.load_url(url_map[model_name])\n",
    "    if load_fc:\n",
    "        model.load_state_dict(state_dict)\n",
    "    else:\n",
    "        state_dict.pop('_fc.weight')\n",
    "        state_dict.pop('_fc.bias')\n",
    "        res = model.load_state_dict(state_dict, strict=False)\n",
    "        assert str(res.missing_keys) == str(['_fc.weight', '_fc.bias']), 'issue loading pretrained weights'\n",
    "    print('Loaded pretrained weights for {}'.format(model_name))\n",
    "    \n",
    "    \n",
    "class MBConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Mobile Inverted Residual Bottleneck Block\n",
    "\n",
    "    Args:\n",
    "        block_args (namedtuple): BlockArgs, see above\n",
    "        global_params (namedtuple): GlobalParam, see above\n",
    "\n",
    "    Attributes:\n",
    "        has_se (bool): Whether the block contains a Squeeze and Excitation layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block_args, global_params):\n",
    "        super().__init__()\n",
    "        self._block_args = block_args\n",
    "        self._bn_mom = 1 - global_params.batch_norm_momentum\n",
    "        self._bn_eps = global_params.batch_norm_epsilon\n",
    "        self.has_se = (self._block_args.se_ratio is not None) and (0 < self._block_args.se_ratio <= 1)\n",
    "        self.id_skip = block_args.id_skip  # skip connection and drop connect\n",
    "\n",
    "        # Get static or dynamic convolution depending on image size\n",
    "        Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n",
    "\n",
    "        # Expansion phase\n",
    "        inp = self._block_args.input_filters  # number of input channels\n",
    "        oup = self._block_args.input_filters * self._block_args.expand_ratio  # number of output channels\n",
    "        if self._block_args.expand_ratio != 1:\n",
    "            self._expand_conv = Conv2d(in_channels=inp, out_channels=oup, kernel_size=1, bias=False)\n",
    "            self._bn0 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "\n",
    "        # Depthwise convolution phase\n",
    "        k = self._block_args.kernel_size\n",
    "        s = self._block_args.stride\n",
    "        self._depthwise_conv = Conv2d(\n",
    "            in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise\n",
    "            kernel_size=k, stride=s, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "\n",
    "        # Squeeze and Excitation layer, if desired\n",
    "        if self.has_se:\n",
    "            num_squeezed_channels = max(1, int(self._block_args.input_filters * self._block_args.se_ratio))\n",
    "            self._se_reduce = Conv2d(in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1)\n",
    "            self._se_expand = Conv2d(in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1)\n",
    "\n",
    "        # Output phase\n",
    "        final_oup = self._block_args.output_filters\n",
    "        self._project_conv = Conv2d(in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False)\n",
    "        self._bn2 = nn.BatchNorm2d(num_features=final_oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "\n",
    "    def forward(self, inputs, drop_connect_rate=None):\n",
    "        \"\"\"\n",
    "        :param inputs: input tensor\n",
    "        :param drop_connect_rate: drop connect rate (float, between 0 and 1)\n",
    "        :return: output of block\n",
    "        \"\"\"\n",
    "\n",
    "        # Expansion and Depthwise Convolution\n",
    "        x = inputs\n",
    "        if self._block_args.expand_ratio != 1:\n",
    "            x = relu_fn(self._bn0(self._expand_conv(inputs)))\n",
    "        x = relu_fn(self._bn1(self._depthwise_conv(x)))\n",
    "\n",
    "        # Squeeze and Excitation\n",
    "        if self.has_se:\n",
    "            x_squeezed = F.adaptive_avg_pool2d(x, 1)\n",
    "            x_squeezed = self._se_expand(relu_fn(self._se_reduce(x_squeezed)))\n",
    "            x = torch.sigmoid(x_squeezed) * x\n",
    "\n",
    "        x = self._bn2(self._project_conv(x))\n",
    "\n",
    "        # Skip connection and drop connect\n",
    "        input_filters, output_filters = self._block_args.input_filters, self._block_args.output_filters\n",
    "        if self.id_skip and self._block_args.stride == 1 and input_filters == output_filters:\n",
    "            if drop_connect_rate:\n",
    "                x = drop_connect(x, p=drop_connect_rate, training=self.training)\n",
    "            x = x + inputs  # skip connection\n",
    "        return x\n",
    "\n",
    "\n",
    "class EfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    An EfficientNet model. Most easily loaded with the .from_name or .from_pretrained methods\n",
    "\n",
    "    Args:\n",
    "        blocks_args (list): A list of BlockArgs to construct blocks\n",
    "        global_params (namedtuple): A set of GlobalParams shared between blocks\n",
    "\n",
    "    Example:\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, blocks_args=None, global_params=None):\n",
    "        super().__init__()\n",
    "        assert isinstance(blocks_args, list), 'blocks_args should be a list'\n",
    "        assert len(blocks_args) > 0, 'block args must be greater than 0'\n",
    "        self._global_params = global_params\n",
    "        self._blocks_args = blocks_args\n",
    "\n",
    "        # Get static or dynamic convolution depending on image size\n",
    "        Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n",
    "\n",
    "        # Batch norm parameters\n",
    "        bn_mom = 1 - self._global_params.batch_norm_momentum\n",
    "        bn_eps = self._global_params.batch_norm_epsilon\n",
    "\n",
    "        # Stem\n",
    "        in_channels = 3  # rgb\n",
    "        out_channels = round_filters(32, self._global_params)  # number of output channels\n",
    "        self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Build blocks\n",
    "        self._blocks = nn.ModuleList([])\n",
    "        for block_args in self._blocks_args:\n",
    "\n",
    "            # Update block input and output filters based on depth multiplier.\n",
    "            block_args = block_args._replace(\n",
    "                input_filters=round_filters(block_args.input_filters, self._global_params),\n",
    "                output_filters=round_filters(block_args.output_filters, self._global_params),\n",
    "                num_repeat=round_repeats(block_args.num_repeat, self._global_params)\n",
    "            )\n",
    "\n",
    "            # The first block needs to take care of stride and filter size increase.\n",
    "            self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "            if block_args.num_repeat > 1:\n",
    "                block_args = block_args._replace(input_filters=block_args.output_filters, stride=1)\n",
    "            for _ in range(block_args.num_repeat - 1):\n",
    "                self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "\n",
    "        # Head\n",
    "        in_channels = block_args.output_filters  # output of final block\n",
    "        out_channels = round_filters(1280, self._global_params)\n",
    "        self._conv_head = Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Final linear layer\n",
    "        self._dropout = self._global_params.dropout_rate\n",
    "        self._fc = nn.Linear(out_channels, self._global_params.num_classes)\n",
    "\n",
    "    def extract_features(self, inputs):\n",
    "        \"\"\" Returns output of the final convolution layer \"\"\"\n",
    "\n",
    "        # Stem\n",
    "        x = relu_fn(self._bn0(self._conv_stem(inputs)))\n",
    "\n",
    "        # Blocks\n",
    "        for idx, block in enumerate(self._blocks):\n",
    "            drop_connect_rate = self._global_params.drop_connect_rate\n",
    "            if drop_connect_rate:\n",
    "                drop_connect_rate *= float(idx) / len(self._blocks)\n",
    "            x = block(x, drop_connect_rate=drop_connect_rate)\n",
    "\n",
    "        # Head\n",
    "        x = relu_fn(self._bn1(self._conv_head(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n",
    "\n",
    "        # Convolution layers\n",
    "        x = self.extract_features(inputs)\n",
    "\n",
    "        # Pooling and final linear layer\n",
    "        x = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        if self._dropout:\n",
    "            x = F.dropout(x, p=self._dropout, training=self.training)\n",
    "        x = self._fc(x)\n",
    "        return x\n",
    "\n",
    "    @classmethod\n",
    "    def from_name(cls, model_name, override_params=None):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        blocks_args, global_params = get_model_params(model_name, override_params)\n",
    "        return EfficientNet(blocks_args, global_params)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name, num_classes=1000):\n",
    "        model = EfficientNet.from_name(model_name, override_params={'num_classes': num_classes})\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def get_image_size(cls, model_name):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        _, _, res, _ = efficientnet_params(model_name)\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def _check_model_name_is_valid(cls, model_name, also_need_pretrained_weights=False):\n",
    "        \"\"\" Validates model name. None that pretrained weights are only available for\n",
    "        the first four models (efficientnet-b{i} for i in 0,1,2,3) at the moment. \"\"\"\n",
    "        num_models = 4 if also_need_pretrained_weights else 8\n",
    "        valid_models = ['efficientnet_b'+str(i) for i in range(num_models)]\n",
    "        if model_name.replace('-','_') not in valid_models:\n",
    "            raise ValueError('model_name should be one of: ' + ', '.join(valid_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Identity. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type EfficientNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Conv2dStaticSamePadding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type MBConvBlock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# def splitfunc(model):\n",
    "#     return [*model]\n",
    "\n",
    "def qk(y_pred, y):\n",
    "    return torch.tensor(cohen_kappa_score(torch.round(y_pred), \n",
    "                                          y, \n",
    "                                          weights='quadratic'), \n",
    "                        device='cuda:0')\n",
    "\n",
    "model = EfficientNet.from_pretrained('efficientnet-b5', num_classes=1)\n",
    "learn = Learner(get_data(448,16),\n",
    "                 model,\n",
    "                 wd=1e-5,\n",
    "                 callback_fns=[ShowGraph,\n",
    "                              partial(SaveModelCallback, every='epoch',name='epoch'),\n",
    "                              partial(SaveModelCallback, every='improvement', monitor='qk', name='classification_best_kappa', mode='max'),\n",
    "                              partial(AccumulateScheduler, n_step=2)],\n",
    "                 path = '../Data/train_processed',\n",
    "                 metrics=[qk,\n",
    "                         mean_squared_error],\n",
    "                 loss_func = MSELossFlat(reduction='sum')\n",
    "                )\n",
    "learn.load('B5_R_224_15')\n",
    "# learn.split(splitfunc)\n",
    "learn.to_fp16()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fit(learner, epochs, lr, start_epoch=0, name='B5_R', res=224, bs=16, div=25):\n",
    "#     learner.data = get_data(size=res,bs=bs)\n",
    "#     learner.to_fp16()\n",
    "#     learner.mixup(stack_y=False)\n",
    "    learner.fit_one_cycle(epochs, lr, pct_start=0.3, div_factor=div, start_epoch=start_epoch)\n",
    "    learner.save(name+'_'+str(res)+'_'+str(start_epoch+epochs))\n",
    "    print('Model saved as '+name+'_'+str(res)+'_'+str(start_epoch+epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='15', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      6.67% [1/15 12:40<2:57:33]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>qk</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.520554</td>\n",
       "      <td>5.593992</td>\n",
       "      <td>0.613048</td>\n",
       "      <td>0.350979</td>\n",
       "      <td>12:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='85' class='' max='627', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      13.56% [85/627 01:38<10:27 7.1155]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with qk value: 0.6130483746528625.\n"
     ]
    }
   ],
   "source": [
    "do_fit(learn, 15, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20.541265, tensor(0.3412), tensor(1.2895)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo shutdown -h 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9963"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,y = learn.get_preds(ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "\n",
    "        ll = cohen_kappa_score(y, X_p, weights='quadratic')\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [1.5, 2.5, 3.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "        print(-loss_partial(self.coef_['x']))\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7385186193750426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[1.616795, 2.374228, 3.305966],\n",
       "       [1.616807, 2.374198, 3.305974],\n",
       "       [1.616856, 2.374212, 3.305958],\n",
       "       [1.616864, 2.374231, 3.305891]]), array([-0.738519, -0.738519, -0.738519, -0.738519]))\n",
       "           fun: -0.7385186193750426\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 79\n",
       "           nit: 30\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([1.616795, 2.374228, 3.305966])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = OptimizedRounder()\n",
    "opt.fit(preds,y)\n",
    "opt.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('../dump/regressor')\n",
    "learn.path = Path('../dump/regressor/')\n",
    "learn.to_fp32()\n",
    "# learn.metrics.pop(0)\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
